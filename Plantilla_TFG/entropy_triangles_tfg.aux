\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{none/global//global/global}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\babel@aux{english}{}
\abx@aux@cite{article_Big_Data}
\abx@aux@segm{0}{0}{article_Big_Data}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:Introduction}{{1}{1}{Introduction}{chapter.1}{}}
\abx@aux@cite{refToInfBottleNeck}
\abx@aux@segm{0}{0}{refToInfBottleNeck}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:fig1b}{{1.1a}{2}{Conceptual representation of a classification process mimicking a communication scheme of boxes.\relax }{figure.caption.6}{}}
\newlabel{sub@fig:fig1b}{{a}{2}{Conceptual representation of a classification process mimicking a communication scheme of boxes.\relax }{figure.caption.6}{}}
\newlabel{fig:fig1a}{{1.1b}{2}{Our end-to-end scheme uses the information regarded from inside the transformation block and we then produce two outputs. First, the predicted (X) which we can use to measure our transformation accuracy. Secondly, the (Z), which contains compressed information about (X)\relax }{figure.caption.6}{}}
\newlabel{sub@fig:fig1a}{{b}{2}{Our end-to-end scheme uses the information regarded from inside the transformation block and we then produce two outputs. First, the predicted (X) which we can use to measure our transformation accuracy. Secondly, the (Z), which contains compressed information about (X)\relax }{figure.caption.6}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Comparison between the classical view of a supervised classification in (a) versus the the model implemented for the purpose of this work in (b).\relax }}{2}{figure.caption.6}\protected@file@percent }
\newlabel{fig:fig1}{{1.1}{2}{Comparison between the classical view of a supervised classification in (a) versus the the model implemented for the purpose of this work in (b).\relax }{figure.caption.6}{}}
\abx@aux@cite{ProgrammerSalaries}
\abx@aux@segm{0}{0}{ProgrammerSalaries}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.1}Budget}{3}{section.1.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {2}Basic Principles}{5}{chapter.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:BasicPrin}{{2}{5}{Basic Principles}{chapter.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.1}Deep Neural Networks}{5}{section.2.1}\protected@file@percent }
\newlabel{fig:fig2a}{{2.1a}{5}{Basic depiction of a simple DNN composed by two hidden layers and a single 2-input/1-output system.\relax }{figure.caption.8}{}}
\newlabel{sub@fig:fig2a}{{a}{5}{Basic depiction of a simple DNN composed by two hidden layers and a single 2-input/1-output system.\relax }{figure.caption.8}{}}
\newlabel{fig:fig2b}{{2.1b}{5}{Normal architecture of an artificial neuron.\relax }{figure.caption.8}{}}
\newlabel{sub@fig:fig2b}{{b}{5}{Normal architecture of an artificial neuron.\relax }{figure.caption.8}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Basic depiction of a simple DNN composed by two hidden layers and a single 2-input/1-output system.\relax }}{5}{figure.caption.8}\protected@file@percent }
\newlabel{fig:fig2}{{2.1}{5}{Basic depiction of a simple DNN composed by two hidden layers and a single 2-input/1-output system.\relax }{figure.caption.8}{}}
\newlabel{eq:artificial neuron}{{2.1}{6}{Deep Neural Networks}{equation.2.1.1}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces The left graph represents a Sigmoid function, while on the right there is a Relu function\relax }}{6}{figure.caption.9}\protected@file@percent }
\newlabel{fig:fig3}{{2.2}{6}{The left graph represents a Sigmoid function, while on the right there is a Relu function\relax }{figure.caption.9}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.2}Information Bottleneck Principle}{7}{section.2.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.3}The Autoencoder}{7}{section.2.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}The Autoencoder Architecture}{7}{subsection.2.3.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Taking into account the Figure \ref  {fig:fig1a}, this diagram depicts the inside of the transformation box. Both the Encoder and the Decoder have symmetric shapes, as well as an expansion layer (the second one in the encoder, the previous one in the decoder) whose goal is to separate the qualities of our data as sort of a preparation for the compression.\relax }}{8}{figure.caption.10}\protected@file@percent }
\newlabel{fig:figure_autoencoder}{{2.3}{8}{Taking into account the Figure \ref {fig:fig1a}, this diagram depicts the inside of the transformation box. Both the Encoder and the Decoder have symmetric shapes, as well as an expansion layer (the second one in the encoder, the previous one in the decoder) whose goal is to separate the qualities of our data as sort of a preparation for the compression.\relax }{figure.caption.10}{}}
\newlabel{eq:artificial neuron}{{2.2}{8}{The Autoencoder Architecture}{equation.2.3.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}The Entropy Triangle}{9}{subsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Introduction}{9}{subsection.2.3.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Example of use of a typical Entropy Triangle. In this case, a Knn classification method is being tested in the triangle.\relax }}{10}{figure.caption.11}\protected@file@percent }
\newlabel{fig:figure_example_et}{{2.4}{10}{Example of use of a typical Entropy Triangle. In this case, a Knn classification method is being tested in the triangle.\relax }{figure.caption.11}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Architecture}{11}{figure.caption.11}\protected@file@percent }
\newlabel{eq:mutual_information_1}{{2.3}{11}{Architecture}{equation.2.3.3}{}}
\newlabel{eq:mutual_information_2}{{2.4}{11}{Architecture}{equation.2.3.4}{}}
\newlabel{eq:virtual_information}{{2.5}{11}{Architecture}{equation.2.3.5}{}}
\newlabel{eq:uniform_entropy_x_y}{{2.6}{11}{Architecture}{equation.2.3.6}{}}
\newlabel{eq:normalised_uniformed}{{2.7}{12}{Architecture}{equation.2.3.7}{}}
\newlabel{eq:complex_space_equation}{{2.8}{12}{Architecture}{equation.2.3.8}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Diagram representing an ET applied to a bivariate distribution.\relax }}{12}{figure.caption.12}\protected@file@percent }
\newlabel{fig:figure_diagram_et}{{2.5}{12}{Diagram representing an ET applied to a bivariate distribution.\relax }{figure.caption.12}{}}
\newlabel{eq:entropy_x_balance}{{2.9}{12}{Architecture}{equation.2.3.9}{}}
\newlabel{eq:entropy_y_balance}{{2.10}{13}{Architecture}{equation.2.3.10}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Schematic of an Entropy Triangle. The labels are placed close to the side of the triangle that is related to the feature mentioned in it.\relax }}{13}{figure.caption.13}\protected@file@percent }
\newlabel{fig:figure_labelled_et}{{2.6}{13}{Schematic of an Entropy Triangle. The labels are placed close to the side of the triangle that is related to the feature mentioned in it.\relax }{figure.caption.13}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.4}Principal Component Analysis}{14}{section.2.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Description}{14}{subsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}PCA and Information Theory}{15}{subsection.2.4.2}\protected@file@percent }
\newlabel{eq:pca_equation}{{2.11}{15}{PCA and Information Theory}{equation.2.4.11}{}}
\newlabel{eq:pca_upper_bound}{{2.12}{15}{PCA and Information Theory}{equation.2.4.12}{}}
\abx@aux@cite{Principe_2000}
\abx@aux@segm{0}{0}{Principe_2000}
\abx@aux@cite{Santana_2016}
\abx@aux@segm{0}{0}{Santana_2016}
\abx@aux@cite{Yu_2019}
\abx@aux@segm{0}{0}{Yu_2019}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {3}State of the Art}{17}{chapter.3}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:StateArt}{{3}{17}{State of the Art}{chapter.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.1}Information Theorethic Learning on Autoencoders}{17}{section.3.1}\protected@file@percent }
\newlabel{eq:Principe_loss_function}{{3.1}{17}{Information Theorethic Learning on Autoencoders}{equation.3.1.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {4}Development}{18}{chapter.4}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:Develop}{{4}{18}{Development}{chapter.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.1}Exploratory Analysis}{18}{section.4.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Iris}{19}{subsection.4.1.1}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces R summary method on Iris.\relax }}{19}{table.caption.14}\protected@file@percent }
\newlabel{tab:table_Iris}{{4.1}{19}{R summary method on Iris.\relax }{table.caption.14}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Using the pairs function summary\relax }}{20}{figure.caption.15}\protected@file@percent }
\newlabel{fig:figure_pairs_iris}{{4.1}{20}{Using the pairs function summary\relax }{figure.caption.15}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Plotting of two different features of Iris with respect to the class label. As it can be seen here, depending of how you organise your data you can get more efficient classifiers and clusters. \relax }}{20}{figure.caption.16}\protected@file@percent }
\newlabel{fig:figure_knn_classifier}{{4.2}{20}{Plotting of two different features of Iris with respect to the class label. As it can be seen here, depending of how you organise your data you can get more efficient classifiers and clusters. \relax }{figure.caption.16}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}MNIST}{21}{subsection.4.1.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Some examples of the images included in the MNIST dataset\relax }}{21}{figure.caption.17}\protected@file@percent }
\newlabel{fig:figure_MNIST}{{4.3}{21}{Some examples of the images included in the MNIST dataset\relax }{figure.caption.17}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces R summary method on MNIST.\relax }}{22}{table.caption.18}\protected@file@percent }
\newlabel{tab:table_MNIST}{{4.2}{22}{R summary method on MNIST.\relax }{table.caption.18}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Ionosphere}{23}{subsection.4.1.3}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces The Ionosphere is one of the main layers composing Earth's atmosphere\relax }}{23}{figure.caption.19}\protected@file@percent }
\newlabel{fig:figure_pairs_iris}{{4.4}{23}{The Ionosphere is one of the main layers composing Earth's atmosphere\relax }{figure.caption.19}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.2}The classifiers}{24}{section.4.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Knn}{24}{subsection.4.2.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces The GGally package also provides useful tools for this types of problems. Here, the correlation between Petal.Length and Petal.Width is proven to be very high, as the plots from Figure \ref  {fig:figure_knn_classifier}\relax }}{25}{figure.caption.20}\protected@file@percent }
\newlabel{fig:figure_knn_classifier_correlation}{{4.5}{25}{The GGally package also provides useful tools for this types of problems. Here, the correlation between Petal.Length and Petal.Width is proven to be very high, as the plots from Figure \ref {fig:figure_knn_classifier}\relax }{figure.caption.20}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Multilayer Perceptron}{25}{subsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {5}Results}{27}{chapter.5}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:Result}{{5}{27}{Results}{chapter.5}{}}
\newlabel{fig:FigA_Autoencoder_MLP}{{5.1a}{27}{Autoencoder and MLP.\relax }{figure.caption.21}{}}
\newlabel{sub@fig:FigA_Autoencoder_MLP}{{a}{27}{Autoencoder and MLP.\relax }{figure.caption.21}{}}
\newlabel{fig:FigB_Autoencoder_KNN}{{5.1b}{27}{Autoencoder and KNN.\relax }{figure.caption.21}{}}
\newlabel{sub@fig:FigB_Autoencoder_KNN}{{b}{27}{Autoencoder and KNN.\relax }{figure.caption.21}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Structure of the Autoencoder and it's classifiers\relax }}{27}{figure.caption.21}\protected@file@percent }
\newlabel{fig:Autoencoder_architecture}{{5.1}{27}{Structure of the Autoencoder and it's classifiers\relax }{figure.caption.21}{}}
\newlabel{fig:FigA_PCA_MLP}{{5.2a}{28}{PCA and MLP.\relax }{figure.caption.22}{}}
\newlabel{sub@fig:FigA_PCA_MLP}{{a}{28}{PCA and MLP.\relax }{figure.caption.22}{}}
\newlabel{fig:FigB_PCA_KNN}{{5.2b}{28}{PCA and KNN.\relax }{figure.caption.22}{}}
\newlabel{sub@fig:FigB_PCA_KNN}{{b}{28}{PCA and KNN.\relax }{figure.caption.22}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Structure of the PCA and it's classifiers\relax }}{28}{figure.caption.22}\protected@file@percent }
\newlabel{fig:PCA_architecture}{{5.2}{28}{Structure of the PCA and it's classifiers\relax }{figure.caption.22}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.1}Iris Dataset}{29}{section.5.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Data Preparation}{29}{subsection.5.1.1}\protected@file@percent }
\newlabel{eq:box-cox}{{5.1}{29}{Data Preparation}{equation.5.1.1}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Using the pairs function on Iris Boxcox\relax }}{30}{figure.caption.23}\protected@file@percent }
\newlabel{fig:figure_pairs_iris}{{5.3}{30}{Using the pairs function on Iris Boxcox\relax }{figure.caption.23}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces R summary method on Iris Box Cox.\relax }}{30}{table.caption.24}\protected@file@percent }
\newlabel{tab:table_Iris_Boxcox}{{5.1}{30}{R summary method on Iris Box Cox.\relax }{table.caption.24}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}The Autoencoder}{31}{subsection.5.1.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Architecture of the Autoencoder in Iris\relax }}{31}{figure.caption.25}\protected@file@percent }
\newlabel{fig:figure_autoencoder_Iris}{{5.4}{31}{Architecture of the Autoencoder in Iris\relax }{figure.caption.25}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}The Classifiers}{33}{subsection.5.1.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Knn on PCA and Autoencoder}{33}{subsection.5.1.3}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Knn example on Iris\relax }}{33}{figure.caption.26}\protected@file@percent }
\newlabel{fig:figure_Knn_Iris}{{5.5}{33}{Knn example on Iris\relax }{figure.caption.26}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Entropy Triangle in Knn in Iris using the Autoencoder\relax }}{34}{figure.caption.27}\protected@file@percent }
\newlabel{fig:figure_Knn_Iris_ET_Auto}{{5.6}{34}{Entropy Triangle in Knn in Iris using the Autoencoder\relax }{figure.caption.27}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Entropy Triangle in Knn in Iris using the PCA\relax }}{35}{figure.caption.28}\protected@file@percent }
\newlabel{fig:figure_Knn_Iris_ET_PCA}{{5.7}{35}{Entropy Triangle in Knn in Iris using the PCA\relax }{figure.caption.28}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Entropy Triangle in Knn in Iris with the testing results\relax }}{36}{figure.caption.29}\protected@file@percent }
\newlabel{fig:figure_Knn_Iris_ET_PCA_Auto}{{5.8}{36}{Entropy Triangle in Knn in Iris with the testing results\relax }{figure.caption.29}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{ MLP on PCA and Autoencoder}{37}{figure.caption.29}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces MLP architecture in Iris for the Autoencoder\relax }}{37}{figure.caption.30}\protected@file@percent }
\newlabel{fig:figure_MLP_Iris_Autoencoder}{{5.9}{37}{MLP architecture in Iris for the Autoencoder\relax }{figure.caption.30}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces MLP Entropy Triangle in Iris for the Autoencoder\relax }}{38}{figure.caption.31}\protected@file@percent }
\newlabel{fig:figure_ET_MLP_Iris_Autoencoder}{{5.10}{38}{MLP Entropy Triangle in Iris for the Autoencoder\relax }{figure.caption.31}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces MLP Entropy Triangle in Iris for the Pca\relax }}{38}{figure.caption.32}\protected@file@percent }
\newlabel{fig:figure_ET_MLP_Iris_Pca}{{5.11}{38}{MLP Entropy Triangle in Iris for the Pca\relax }{figure.caption.32}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces MLP Entropy Triangle total testing result\relax }}{39}{figure.caption.33}\protected@file@percent }
\newlabel{fig:figure_ET_Total_MLP_Iris}{{5.12}{39}{MLP Entropy Triangle total testing result\relax }{figure.caption.33}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.2}Ionosphere Dataset}{40}{section.5.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Data Preparation}{40}{subsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}The Autoencoder}{40}{subsection.5.2.2}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Ionosphere Autoencoder layers of the encoder.\relax }}{40}{table.caption.34}\protected@file@percent }
\newlabel{tab:table_Ionosphere_auto_encoder}{{5.2}{40}{Ionosphere Autoencoder layers of the encoder.\relax }{table.caption.34}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces Ionosphere Autoencoder layers of the decoder.\relax }}{41}{table.caption.35}\protected@file@percent }
\newlabel{tab:table_Ionosphere_auto_decoder}{{5.3}{41}{Ionosphere Autoencoder layers of the decoder.\relax }{table.caption.35}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Knn on PCA and Autoencoder}{41}{subsection.5.2.3}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces Entropy Triangle in Knn in Ionosphere using the Autoencoder\relax }}{42}{figure.caption.36}\protected@file@percent }
\newlabel{fig:figure_Knn_Ionosphere_ET_Auto}{{5.13}{42}{Entropy Triangle in Knn in Ionosphere using the Autoencoder\relax }{figure.caption.36}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.14}{\ignorespaces Entropy Triangle in Knn in Ionosphere using the PCA\relax }}{42}{figure.caption.37}\protected@file@percent }
\newlabel{fig:figure_Knn_Ionosphere_ET_PCA}{{5.14}{42}{Entropy Triangle in Knn in Ionosphere using the PCA\relax }{figure.caption.37}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.4}MLP on PCA and Autoencoder}{43}{subsection.5.2.4}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.15}{\ignorespaces Entropy Triangle in the MLP in Ionosphere using the Autoencoder\relax }}{43}{figure.caption.38}\protected@file@percent }
\newlabel{fig:figure_MLP_Ionosphere_ET_Auto}{{5.15}{43}{Entropy Triangle in the MLP in Ionosphere using the Autoencoder\relax }{figure.caption.38}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.16}{\ignorespaces Entropy Triangle in the MLP in Ionosphere using the PCA\relax }}{44}{figure.caption.39}\protected@file@percent }
\newlabel{fig:figure_MLP_Ionosphere_ET_PCA}{{5.16}{44}{Entropy Triangle in the MLP in Ionosphere using the PCA\relax }{figure.caption.39}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.17}{\ignorespaces Entropy Triangle in Ionosphere with the total test fold value\relax }}{44}{figure.caption.40}\protected@file@percent }
\newlabel{fig:figure_Total_Ionosphere_ET}{{5.17}{44}{Entropy Triangle in Ionosphere with the total test fold value\relax }{figure.caption.40}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.3}MNIST Dataset}{45}{section.5.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Data Preparation}{45}{subsection.5.3.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}The Autoencoder}{45}{subsection.5.3.2}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces MNIST Autoencoder layers of the encoder.\relax }}{45}{table.caption.41}\protected@file@percent }
\newlabel{tab:table_MNIST_auto_encoder}{{5.4}{45}{MNIST Autoencoder layers of the encoder.\relax }{table.caption.41}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {5.5}{\ignorespaces MNIST layers of the decoder.\relax }}{45}{table.caption.42}\protected@file@percent }
\newlabel{tab:table_MNIST_auto_decoder}{{5.5}{45}{MNIST layers of the decoder.\relax }{table.caption.42}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}MLP on PCA and Autoencoder}{46}{subsection.5.3.3}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {5.6}{\ignorespaces MNIST MLP layers of the Autoencoder\relax }}{46}{table.caption.43}\protected@file@percent }
\newlabel{tab:table_MNIST_MLP_auto}{{5.6}{46}{MNIST MLP layers of the Autoencoder\relax }{table.caption.43}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {5.7}{\ignorespaces MNIST MLP layers of the PCA\relax }}{46}{table.caption.44}\protected@file@percent }
\newlabel{tab:table_MNIST_MLP_pca}{{5.7}{46}{MNIST MLP layers of the PCA\relax }{table.caption.44}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.18}{\ignorespaces Entropy Triangle in MLP in MNIST using the Autoencoder\relax }}{47}{figure.caption.45}\protected@file@percent }
\newlabel{fig:figure_MLP_MNIST_ET_Auto}{{5.18}{47}{Entropy Triangle in MLP in MNIST using the Autoencoder\relax }{figure.caption.45}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.19}{\ignorespaces Entropy Triangle in MLP in MNIST using the PCA\relax }}{47}{figure.caption.46}\protected@file@percent }
\newlabel{fig:figure_MLP_MNIS_ET_PCA}{{5.19}{47}{Entropy Triangle in MLP in MNIST using the PCA\relax }{figure.caption.46}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.20}{\ignorespaces Entropy Triangle in MLP in MNIST total testing result\relax }}{48}{figure.caption.47}\protected@file@percent }
\newlabel{fig:figure_MLP_MNIS_ET_Total}{{5.20}{48}{Entropy Triangle in MLP in MNIST total testing result\relax }{figure.caption.47}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion}{49}{chapter.6}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:Conclusion}{{6}{49}{Conclusion}{chapter.6}{}}
\abx@aux@refcontextdefaultsdone
\abx@aux@defaultrefcontext{0}{article_Big_Data}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{refToInfBottleNeck}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{ProgrammerSalaries}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Principe_2000}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Santana_2016}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Yu_2019}{none/global//global/global}
\ttl@finishall
